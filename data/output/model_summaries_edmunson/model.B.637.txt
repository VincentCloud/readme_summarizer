模型设计的指导 修改采样的方案，通过每隔几轮的更新候选集合进行采样 采样中当选择了xa xp之后，如何确定选择的xn是一个可以提升结果的点 细化case方案，重新定制损失函数，把损失函数可视化出来 设计xa xp xn之间的矢量信息，求出夹角方向值，重新设计损失函数 通过增大的batch信息，将类内误差和类间误差添加到损失函数中去 问题以及解决？ 所有的训练样本都是根据随机选择的，其中存在部分数据是很难被直接选择到的，导致10分类的分类器的分类性能下降 改进样本构造的方案，使得所有的样本都可以进入分类器进行训练 实验结果 todolist x 使用res50提取图像的特征 x 编写孪生网络进行测试 x 编写triple loss网络，并进行测试 重新设计triple loss网络训练样本的构造 x 添加了基于聚类中心的anchor选择和在给定半径之外的正负样本的选择 x 添加了针对训练样本中之间的方向条件进行选择 添加针对query列表候选集进行训练样本选择的策略 根据triplemodel输入的数据中可以转化成pairwise的排序问题 x 将每次训练出得模型结果保存成文件便于后续分析 结果图中，聚类不够紧凑 针对数据采样策略的修改 x 在采样时使用一个set，保证被采样过的样本不能在被采样一次，直到没有可采样数据后，结束这一轮的训练 x 每一个batch采样时，将记录每个样本被采样的次数，每次会得到一个分布，将分布改成概率p，下一次按照1p去进行采样 损失函数为，在训练段记录为0的样本，这些样本对整体训练没有梯度的贡献，进而指导采样 每一轮训练后，会得到全量数据的距离矩阵，将距离矩阵转换成概率矩阵对采样端进行结果指导mcmc 修改loss函数策略 x 关注到xp到xa的距离的控制 是否可以引入em算法，对进行二维变量的混合高斯估计 当选择的数据samplexa xp xn为一下情况，样本失效目标是max0.0 distp distn margin distn too large distp too small margin too small the categories of positive and negative samples are not close neighbors the selection of positive and negative samples is not on the same side x 添加hash loss function 每次使用2000个triple样本进行训练，相邻的两个epoch得到的预测结果差异很大，如何较好的控制每次聚类的结果，这个确实很重要？ x 使用softmax loss center loss进行训练，得到模型 reference list deep learning of binary hash codes for fast image retrieval deep relative distance learning tell the difference between similar vehicles deep supervised discrete hashing deep supervised hashing for fast image retrieval facenet a unified embedding for face recognition and clustering fast training of tripletbased deep binary embedding networks hardaware deeply cascaded embedding hashnet deep learning to hash by continuation fast supervised hashing with decision trees for highdimensional data simultaneous feature learning and hash coding with deep neural networks learning to hash with binary reconstructive embeddings